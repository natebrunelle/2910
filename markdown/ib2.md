---
title: Mitigating Implicit Bias
...

[Implicit bias](ib.html) is an inevitable side-effect of having a working brain.
We cannot remove them, but there are various things we can do to help mitigate their influence on our decision making.

# Awareness

Being aware of your implicit biases can help create an "aligns with bias" schema,
which in turn can create a counter-bias force.
Counter-biases can theoretically completely remove the bias of an estimator,
but in practice getting their weight exactly right is not easily done,
sometimes resulting in under- or over-compensating.

How do you learn about your implicit biases?

- Ask others. It is easier to see biases in others than in yourself.
- Take training or tests. [Project Implicit](https://implicit.harvard.edu/implicit/) is a popular example test.^[Note: implicit biases are subconscious phenomena, which means that if you are relaxed and focused your conscious mind will bypass them. Project Implicit and many related tests use speed to try to avoid conscious interference, assuming that when an action aligns with your subconscious biases you'll be able to do it more rapidly than when it does not align with them. Not everyone agrees with this speed-oriented test design, but it is simple to create and measure and may be a good estimator.]
- Measure your decisions, look for biased results, and then ask why they occurred.

Note that implicit biases may be things you are entirely unaware of.
For example, many people are unaware that they have a bias towards picking tall, deep-voiced people as being "more mature," with all of the positive connotations of trust, respect, deference, and so on that come with that.
We might expect this bias to be held by every brain, being related to our ability to distinguish children (who tend to be short with high-pitched voices) from adults (who tend to be taller and deeper in voice),
but it is not often discussed or acknowledged compared to some other biases.

# Algorithm

One way to avoid implicit-bias-biased decisions is to make decisions according to some predetermined process or algorithm.
Algorithms themselves can be [biased](https://en.wikipedia.org/wiki/Algorithmic_bias),
but they can also be designed to be unbiased.

A few examples algorithm used by TAs to make decisions:

- Every student gets 5 minutes of help
- Use a queue to decide whom to help next
- Walk a path that passes each student, asking each in turn if they need help
- Open each help with the same question, and use the same follow-up questions for each of the most common answers

The more time you spend as a TA, the more likely you are to develop habits to help you with common tasks.
It is worth periodically reviewing your behaviors and seeing if there is room to add a new consciously-unbiased algorithm to your decision making procedures.

# Mental Filter

A key concept of implicit bias is that your brain averages all of your schemata's contributions to a decision.
While this cannot be fully changed, you can adjust the weighting of those different components.

One strategy I have found helpful^[This is my personal experience; I have not found this strategy studied in the academic literature on implicit bias.]
is to consciously ask myself "What would *person-I-respect* do?"
My brain has a schemata for the decisions made by people I interact with often,
and I find it can effectively provide a different weighted average
that better reflects my image of them.
It doesn't matter if I am right to respect them; what matters is that this may help down-weight the contributions of schemata that I don't think a respected friend would include.

I personally use this often, using a respected colleague at work
to ask myself "is this how they'd word this email?",
"would they approve of this exam?",
"is this who they'd hire?",
and so on.
Over time, I find that I gradually start acting according to this filtered decision process on my own without needing the conscious pause to ask myself this question.
